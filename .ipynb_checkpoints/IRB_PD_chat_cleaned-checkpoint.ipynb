{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db10bb2",
   "metadata": {},
   "source": [
    "# IRB PD Model – Cleaned Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7509ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c93a78",
   "metadata": {},
   "source": [
    "## Data Loading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc209d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\mel\\1. IRK\\hypo_credit_risk_dataset1.csv\")\n",
    "\n",
    "df['log_annual_income'] = np.log1p(df['annual_income'])\n",
    "df['loan_to_income_ratio'] = df['exposure_at_default'] / df['annual_income']\n",
    "df['credit_score_bin'] = pd.qcut(df['credit_score_internal'], q=5, labels=False)\n",
    "df['age_bucket'] = pd.cut(\n",
    "    df['age_years'],\n",
    "    bins=[18, 30, 45, 60, 10000],\n",
    "    labels=[\"18-30\", \"31-45\", \"46-60\", \"61+\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a1df9",
   "metadata": {},
   "source": [
    "## Visual Check: Default Rate by Rating Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a02d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rating_default_rate = df.groupby('rating_grade')['default_flag'].mean()\n",
    "sns.barplot(x=rating_default_rate.index, y=rating_default_rate.values)\n",
    "plt.title(\"Default Rate by Rating Grade\")\n",
    "plt.ylabel(\"Default Rate\")\n",
    "plt.xlabel(\"Rating Grade\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd8af0",
   "metadata": {},
   "source": [
    "## Train/Test Split Based on Snapshot Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_year = 2024\n",
    "train_df = df[df['snapshot_year'] < val_year].copy()\n",
    "test_df = df[df['snapshot_year'] == val_year].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604a45e",
   "metadata": {},
   "source": [
    "## One-Hot Encoding + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_vars = ['customer_region', 'industry_sector', 'housing_status', 'marital_status']\n",
    "\n",
    "X_train_encoded = pd.get_dummies(train_df, columns=categorical_vars, prefix=categorical_vars)\n",
    "X_test_encoded = pd.get_dummies(test_df, columns=categorical_vars, prefix=categorical_vars)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "X_train_encoded['customer_type_num'] = (train_df['customer_type'] == 'retail').astype(int)\n",
    "X_test_encoded['customer_type_num'] = (test_df['customer_type'] == 'retail').astype(int)\n",
    "\n",
    "y_train_encoded = train_df['default_flag']\n",
    "y_test_encoded = test_df['default_flag']\n",
    "\n",
    "drop_cols = ['customer_type', 'customer_region', 'industry_sector', 'housing_status', 'marital_status']\n",
    "X_train_encoded.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "X_test_encoded.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "X_train_encoded = X_train_encoded.select_dtypes(include=[np.number])\n",
    "X_test_encoded = X_test_encoded.select_dtypes(include=[np.number])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379dce2",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "means = X_train_scaled.mean(axis=0)\n",
    "stds = X_train_scaled.std(axis=0)\n",
    "\n",
    "scaling_check = pd.DataFrame({'mean': means, 'std': stds}, index=X_train_encoded.columns)\n",
    "deviations = scaling_check[(abs(means) > 0.05) | (abs(stds - 1) > 0.05)]\n",
    "\n",
    "if deviations.empty:\n",
    "    print(\"Scaling approved. All means ≈ 0 and stds ≈ 1.\")\n",
    "else:\n",
    "    print(\"Some features deviate from expected scaling:\")\n",
    "    display(deviations.round(3))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
